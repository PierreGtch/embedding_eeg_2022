paradigm_params:
  base:
    events: null
    tmin: 0.0
    tmax: null
    baseline: null
    resample: 128
    n_classes: 4
    channels:
      - FC5
      - FC1
      - FC2
      - FC6
      - C3
      - C4
      - CP5
      - CP1
      - CP2
      - CP6
      - FC3
      - FCz
      - FC4
      - C5
      - C1
      - C2
      - C6
      - CP3
      - CPz
      - CP4
      - FFC5h
      - FFC3h
      - FFC4h
      - FFC6h
      - FCC5h
      - FCC3h
      - FCC4h
      - FCC6h
      - CCP5h
      - CCP3h
      - CCP4h
      - CCP6h
      - CPP5h
      - CPP3h
      - CPP4h
      - CPP6h
      - FFC1h
      - FFC2h
      - FCC1h
      - FCC2h
      - CCP1h
      - CCP2h
      - CPP1h
      - CPP2h
  single_band:
    fmin: 0.5
    fmax: 40.0
  filter_bank:
    filters:
      - [4, 8]
      - [8, 12]
      - [12, 16]
      - [16, 20]
      - [20, 24]
      - [24, 28]
      - [28, 32]
      - [32, 36]
      - [36, 40]
evaluation_params:
  base:
    random_state: 12
  within_session:
    n_perms: null
    data_size: null
net_params:
  # random_state: 12
  batch_size: 50
  max_epochs: 2
  lr: 0.001  # this is actually the maximal learning rate of the OneCycle LR scheduler.
  module:
    final_conv_length: auto
    pool_mode: mean
    F1: 8
    D: 2
    F2: 16
    kernel_length: 64
    third_kernel_size: (8, 4)
    drop_prob: 0.5
  iterator_train:
    shuffle: true
    drop_last: false
